% Faz com que o ínicio do capítulo sempre seja uma página ímpar
\cleardoublepage
% Inclui o cabeçalho definido no meta.tex
\pagestyle{fancy}
% Números das páginas em arábicos
\pagenumbering{arabic}

%espaco entre linhas
\onehalfspacing

\chapter{Introdução}\label{intro}

\section{Introdução ao balanceamento de carga}\label{cap1:intro}

%Grid
A computação paralela vem sendo amplamente utilizada para atender necessidades de aplicações que exigem muito poder computacional. A cada dia surgem propostas de novas máquinas e modelos de arquiteturas paralelas, com diferentes quantidades de processadores, topologias e redes de interconexão. O universo de arquiteturas existentes é grande e elas são normalmente agrupadas como: SIMD e MIMD. Máquinas SIMD possuem um único fluxo de instrução aplicados a múltiplos dados e normalmente são específicas para um tipo de aplicação. As MIMD possuem multiplos fluxos de instrução sendo executados em paralelo. Atualmente as máquinas MIMD são as mais utilizadas e podem ser divididas como: Multi Processadores Simétricos (SMP), Vetoriais, Massivamente paralelas (MPP), agregados de computadores \emph{(Clusters)} e Grades computacionais \emph{(Grids)}. 

As máquinas SMP, Vetoriais e MPP normalmente fornecem ambientes para programação e uso eficiente, porém são arquiteturas proprietárias e com alto custo de montagem e manutenção. Já os clusters e os grids consistem basicamente de diversas unidades de processamento, que podem ser independentes, interconectadas por uma rede de comunicação. As principais vantagens nesse modelo são custos baixos e alta escalabilidade, isto  é, a possibilidade de facilmente alterar, ao longo do tempo, a quantidade de unidades de processamento da arquitetura. No entanto, a computação é baseada em memória distribuída, ou seja, cada unidade de processamento apresenta a sua própria memória e necessita programação da troca de informações entre os processadores, o que pode ser uma tarefa muito complexa.

%gpus
As GPUs vêm se mostrando uma excelente alternativa na área de computação de
alto-desempenho para aplicações que exigem um alto grau de
paralelismo~\citep{gpu}. GPUs modernas podem possuir milhares de núcleos, cada um
deles bastante simples, mas que utilizados em paralelo geram um alto poder
computacional~\citep{cuda}.

Muitas aplicações já utilizam o poder de processamento das GPUs, como mecânica
dos fluidos~\citep{fluido}, visualização científica~\citep{visualizacao},
aprendizado de máquina~\citep{Aprendizado}, bioinformática~\citep{rozante} e redes
neurais~\citep{siang}. Devido ao relativo baixo custo de placas gráficas contendo
GPUs, sua utilização é uma ótima alternativa para pesquisadores pertencentes a
instituições com poucos recursos financeiros e com grande necessidade de
recursos computacionais.

Em diversos casos, o uso de GPUs ocasionam ganhos superiores a 100 vezes, quando
comparado às CPUs tradicionais~\citep{Vouzis15012011}. No entanto, para muitos problemas, o uso de uma
única GPU ainda limita o tamanho e complexidade do problema que pode ser
resolvido. Neste caso, é possível utilizar múltiplas GPUs localizados em
diferentes computadores, como em \emph{clusters} de GPUs~\citep{raphael,
  cluster}.

Os \emph{clusters} de GPUs são normalmente homogêneos, no qual todas as
máquinas apresentam a mesma configuração de hardware. O desenvolvimento de um
aplicativo para executar em um \emph{cluster} de GPU é um desafio, porque o
programador tem de empregar uma biblioteca de programação paralela, como MPI,
além de usar a plataforma CUDA. Existem alguns esforços para oferecer alguns
modelos de programação~\citep{appCientificas, wave} e bibliotecas~\citep{snucl,
  Flat} para o desenvolvimento de aplicações para \emph{clusters} de GPUs. No
entanto, a forma mais utilizada para programação para \emph{clusters} de GPUs
é combinando CUDA e MPI.

Já no caso de \emph{clusters} heterogêneos é necessário distribuir a carga
computacional entre as GPUs. Desenvolver um mecanismo que funcione de modo
eficiente para qualquer aplicação é difícil, mas pode-se restringir o mecanismo
para alguns tipos específicos de aplicações. Por exemplo, podemos considerar
aplicações que possuem um conjunto de dados que podem ser particionados entre as
GPUs, utilizando o método de decomposição de domínio~\citep{CNM:CNM1640090307}. Neste caso, cada GPU fica
responsável por uma parte dos dados da aplicação. Muitas aplicações científicas
se encaixam neste grupo, incluindo bioinformática~\citep{rozante}, redes
neurais~\citep{siang}, química~\citep{anastas2000green}, física~\citep{delpech2009reactor} e ciência dos materiais~\citep{da2007desenvolvimento}. 

Para este tipo de aplicação, a distribuição da carga em \emph{clusters}
homogêneos de GPUs é frequentemente obtida com uma divisão simples dos dados de
entre as GPUs. No entanto, com grupos heterogêneos de GPUs, esta situação é mais
difícil. Existem atualmente várias arquiteturas existentes, como a Tesla, Fermi
e Kepler. Essas arquiteturas apresentam diferentes organizações de núcleos e
multiprocessadores, quantidades de memória compartilhada por núcleo e
velocidades de memória. Devido a essas diferenças, uma divisão da carga com base
em simples heurísticas, tal como o número de núcleos na GPU não é eficaz. Na
verdade, isso pode levar a um maior tempo de execução~\citep{raphael} comparado a
simples ideia de dividir a carga igualmente entre as GPUs heterogêneas. Em um
cenário mais geral, uma aplicação pode ter vários \emph{kernels}, cada um com
dependências não-lineares entre o tempo de execução e o tamanho de entrada.

Apesar da importância do tema, poucos trabalhos apresentam algoritmos de
balanceamento de carga em sistemas heterogêneos baseados em GPUs. Os existentes
são \emph{frameworks} que requerem a reescrita da aplicação para que seja
possível a execução nestes \emph{clusters}.

\citep{acosta} propuseram um algoritmo de balanceamento de carga dinâmico que interativamente tenta encontrar uma boa distribuição do trabalho entre GPUs durante o exe- cução da aplicação. Uma biblioteca se concentra nas diferenças de tempos de códigos paralelos, com base em um esquema iterativo. É um esquema descentralizado em que as sincronizações são feitas a cada iteração para determinar se há uma necessidade de reequilibrar a carga. Cada processador executa uma redistribuição da carga de trabalho de acordo com o tamanho da tarefa atribuída e as capacidades do processador atribuído. O balanceamento de carga é obtido através da comparação do tempo de execução da tarefa atual para cada processador com a redistribuição da tarefa subseqüente, se o tempo gasto para precessar a tarefa atingir um limite a redistribuição de carga é feito. 

Um algoritmo estático que determina a distribuição antes de iniciar a execução da aplicação, utilizando os perfis estáticos de execuções anteriores, também foi proposta~\citep{raphael}. O algoritmo foi avaliado usando uma simulação de rede neural. O algoritmo encontra a distribuição de dados que minimiza o tempo de execução da aplicação, com base em perfis de execuções anteriores, assegurando que todas as GPUs para passar mesma quantidade de tempo que executa o processamento. 

O  (HDSS)~\citep{HDSS} fornece um algoritmo de balanceamento de carga dinâmico, dividido em duas fases. O primeiro é a fase adaptativo, que determina pesos que refletem a velocidade de cada processador. Esses pesos são determinados com base em ajustes de curvas logarítmicas em gráficos de velocidade de processamento. Estas ponderações são utilizadas durante a fase de acabamento, onde se divide nas iterações restantes entre as GPUs com base nos pesos relativos de cada GPU.


\section{Objetivos e Contribuições}\label{cap1:objetivos}

O presente trabalho tem como objetivo o desenvolvimento de um algoritmo de balanceamento de carga para aglomerados de GPUs heterogêneos, ou seja, todo o planejamento e respaldo para a criação de um algoritmo eficiente que minimize o tempo total de processamento.

O algoritmo será implementando usando o \textit{framework} denominado StarPu, que é voltado para aglomerados. A estrutura do arcabouço facilitará a implementação do algoritmo.

Por fim, serão feitos testes de comparação de desempenho do algoritmo desenvolvido com os atuais algoritmos para a execução das mesmas tarefas.


\section{Organização da Dissertação}\label{cap1:organizacao}

Esta dissertação se divide em seis capítulos. O Capítulo 2 apresenta a fundamentação utilizada neste trabalho. Neste capítulo são discutidos os conceitos, classes e técnicas de escalonamento. O Capítulo 3 descreve os trabalhos relacionados ao que tange o escalonamento de tarefas e mais especificadamente ao balanceamento de carga em aglomerados heterogêneos.
O Capítulo 4, apresenta o detalhadamento do algoritmo proposto. O capitulo 5, mostra detalhes de implementação, e os problemas testados. 
O Capítulo 6 apresenta os resultados e conclusões desta dissertação, assim como sugestões de trabalhos futuros.
Por fim o capítulo 7 apresenta o plano de trabalho, das atividades já desenvolvidas e as próximas atividades a serem desenvolvidas.


