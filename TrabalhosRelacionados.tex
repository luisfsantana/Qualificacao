\pagestyle{empty}
\cleardoublepage
\pagestyle{fancy}

%espaco entre linhas
\onehalfspacing

\chapter{Trabalhos Relacionados}\label{cap2}


A crescente demanda de processamento de informação levantou especial interesse no campo de balanceamento de carga. Muitos trabalhos foram feitos neste campo buscando o aprimoramento de técnicas e o tratamento específico para os problemas de escalonamento e balanceamento mais recorrentes, em especial em arquiteturas heterogêneas. Neste capítulo são abordados os trabalhos que serviram como base para esta dissertação ou que exploraram algum assunto diretamente relacionado ao tema aqui apresentado. 

As novas possibilidades trazidas com as novas arquiteturas de GPU
estão instigando pesquisadores a rever o problema do balanceamento de
carga neste novo contexto. Apesar do balanceamento de carga ser crítico para o desempenho de aplicações paralelas, como no caso de aplicações gráficas~\citep{kdtree, ray}, ainda não há na literatura muitos estudos sobre balanceamento de carga em GPUs.

\citep{graphics} analisaram várias estratégias de balanceamento de carga estática
e dinâmica para um problema de partição de octree em GPUs. O balanceamento de
carga é realizado internamente em uma única GPU, sem interação com a CPU. Neste trabalho foram testados os seguintes métodos de balanceamento de carga: (1) lista de tarefas estática, que consiste em dividir os dados em lista de tarefas, no qual cada unidade processamento retira uma tarefa da lista e executa-a, o trabalho termina quando a lista estiver vazia e o controle é retornado a CPU. (2) Lista de tarefas dinâmica bloqueante, que consiste em uma lista de tarefas que em tempo de execução pode receber novas tarefas. É bloqueante pois apenas um bloco de threads pode acessar a lista em um dado tempo. (3) Lista de tarefas dinâmica lock-free: consiste  
em fazer com seja controlado o acesso na inserção  e remoção de tarefas na lista, dois blocos de threads podem acessar a lista, um para inserir e outro para remover tarefas, melhorando o paralelismo. (4) Roubo de tarefas: cada unidade de processamento recebe um conjunto de tarefas e quando completa as tarefas do conjunto tenta roubar uma tarefa de outra unidade de processamento que ainda não concluiu suas tarefas atribuídas. Se uma unidade cria uma nova tarefa, a unidade acrescenta a seu próprio conjunto local de tarefas. Este estudo se diferencia do apresentado, pois é analisado apenas o comportamento em GPUs, não adicionando CPUs e clusters. 

Em outro estudo~\citep{tasks} com balanceamento de carga em GPUs, os autores propõem uma fila que mescla as cargas de trabalho que são subutilizados na GPU podendo ser executadas simultaneamente em uma GPU, através da fusão em um \textit{super-kernel}. No entanto, esta fusão precisa ser realizada estaticamente, e assim o equilíbrio dinâmico de carga não pode ser sempre garantido. O trabalho foca somente em GPUs, apesar de apresentar a característica dinâmica, de modificar o escalonamento em tempo de execução.

\citep{acosta} propôs um algoritmo de balanceamento de carga
dinâmico, que busca, interativamente, uma boa distribuição de trabalho entre as
GPUs durante a execução da aplicação. O algoritmo de balanceamento consiste em obrigar todos os processadores a realizarem uma chamada a uma função chamada ULL\_MPI\_calibrate(). Nesta chamada todos os processadores realizam as mesmas operações de balanceamento, que são as seguintes. (1) Cada processador precisa determinar o tempo que levou para processar uma certa quantia de dados em cada iteração. (2) Testar se o tempo para processar é maior que um certo limiar, se sim, balancear a carga entre os processadores. (3) Calcular o que é chamado de \emph{relative power}, que corresponde ao relacionamento entre o tempo gasto para processar um certo tamanho de dados em função do tamanho do problema. (4) Por fim, calcular a quantidade de dados atribuida a cada processador, assim todos os processadores realizam o próprio balanceamento de carga. Os autores avaliaram os problemas de
multiplicação de matrizes e alocação de recursos. O método iterativo pode
demorar para atingir uma distribuição de carga adequada, reduzindo o desempenho
da aplicação. Além disso, não é possível utilizar informações relativas a tempos
de execução anteriores para gerar um perfil de execução para as futuras
execuções da aplicação. O trabalho é similar ao nosso, pois apresenta o conceito de limiar que determina se deve ser feito o balanceamento da carga.

Em outro trabalho, \citep{raphael} propõe um algoritmo que determina a
distribuição, antes do início da execução da aplicação, usando perfis estáticos
obtidos em execuções anteriores. Antes de iniciar o processamento da carga o algoritmo fornece entradas de tamanhos diferentes às GPUs, e baseado nesses valores de tempos, encontra um tamanho de entrada que faz com que o tempo gasto por todos as GPUs seja o mesmo.
O algoritmo foi avaliado para uma aplicação de
redes neurais de grande escala. O algoritmo encontra a distribuição de dados que
minimiza o tempo de execução da aplicação, garantindo que todas as GPUs gastem a
mesma quantia de tempo realizando o processamento de \emph{kernels}. Esta
abordagem, entretanto, não permite alterações dinâmicas na distribuição dos
dados. 

Em~\citep{Clarke:2012:HPA:2402420.2402479}  os autores fizeram um balanceamento de carga dinâmico heterogêneo baseado na partição de matrizes, ou seja, apenas serve para problemas que envolvem matrizes. Há uma divisão da matriz entre as unidades, que se subdivide entre as subunidades e assim por diante. 

No trabalho \citep{chen2010dynamic}, os autores propõe uma solução baseada em tarefas para o balanceamento de carga para sistema com várias GPUs. Atualmente no paradigma de programação em CUDA, para executar multiplas tarefas, o processo na CPU tem que lançar sequencialemente múltiplos \emph{kernels} e o hardware é responsável por arranjar como os kernel rodarão na GPU, isto faz com que se execute um kernel, o controle retorne para a CPU, que submete um novo kernel e assim por diante. No balanceamento de carga propoto neste trabalho, a ideia é manter os blocos de threads sempre ativos e fazer com que uma fila de tarefas seja criada. Para cada GPU uma fila de tarefas é criada e assim multiplas GPUs realizam o processamento da carga. O trabalho é diferente do nosso, pois é voltado para o conceito de tarefas, em vez de decomposição de domínio, além do que no nosso trabalho é considerado CPUs como elementos de processamento, também de uma forma mais geral tem o foco no algoritmo de balanceamento de carga, não em características da GPU.


Por fim, \citep{HDSS} desenvolveram o que eles chamaram de Heterogeneous Dynamic Self-Scheduler (HDSS) que fornece um algoritmo de balanceamento de carga dinâmico, dividido em duas fases. A primeira fase é a fase adaptativa, que determina pesos que refletem a velocidade de cada processador. Esses pesos são determinados com base em ajustes de curvas logarítmicas em gráficos de velocidade de processamento. Estas ponderações são utilizadas durante a fase de acabamento, que é a segunda fase, onde é dividido os dados a serem processados nas iterações restantes entre as GPUs, com base nos pesos relativos de cada GPU. As principais diferenças com o nosso algoritmo é que  eles restringem os modelos de execução a curvas logaritmicas, que são apropriados para GPUs, mas não são apropriadas para CPUs na faixa de interesse. Além disso, nosso algoritmo pode realizar ajustes até o fim da execução.



